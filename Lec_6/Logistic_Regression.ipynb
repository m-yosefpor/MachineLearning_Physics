{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "6cC5C4jjKNjd",
        "vUruVCz_8Y40"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sraeisi/MachineLearning_Physics/blob/master/Lec_6/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pyRSpnrE8Y3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TIBU-WoF8Y3Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6cC5C4jjKNjd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression: The simplest Neural Network (NN)"
      ]
    },
    {
      "metadata": {
        "id": "praJkn8I8Y3X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We start with a simple Logistic regression. \n",
        "\n",
        "We can use computation graphs for representation which would look like:\n",
        "\n",
        "![Simple Logistic Regression](https://www.dropbox.com/s/5ql7mpu9uwim8xk/computationGraph_LR.png?dl=1 )\n",
        "\n",
        "For our purposses, it is more convenient to seperate the parameters\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/pxrmeyz3uwwb95i/computationGraph_LR_2.png?dl=1)\n",
        "\n",
        "We can simplify this a bit to get\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/8hspbepvubgu1ia/computationGraph_LR_simplified.png?dl=1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "l83ITgxU8Y3Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "Ideally, we should train the estimator and find the\n",
        "w and b that minimizes the loss. However, the following\n",
        "function makes no assumption about the w and b. \n",
        "The inputs are numpy arrays and their shapes are\n",
        "x: (1, n_f)\n",
        "w: (1, n_f)  \n",
        "b: (1  , 1) \n",
        "'''\n",
        "def log_reg_predict(x, w, b ):\n",
        "    return sigmoid( np.dot(x, w.T) + b )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HIdaSmaT8Y3f",
        "colab_type": "code",
        "outputId": "9a39ce63-41b5-43e7-fffe-1d415b80d821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "x = np.random.uniform(-1,1,size=[1,2])\n",
        "w = np.random.uniform(-1,1,size=[1,2])\n",
        "b = np.random.uniform(-1,1,size=[1,1])\n",
        "predicted_y = log_reg_predict(x,w,b)\n",
        "predicted_y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18551557]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "G7oWbXBD-hSC",
        "colab_type": "code",
        "outputId": "c0ebabc1-ea51-46d2-b834-fa834c76911c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "### This would work with a list of samples.\n",
        "n_s = 100  # number of samples\n",
        "\n",
        "x = np.random.uniform(-1,1,size=[n_s,2])\n",
        "w = np.random.uniform(-1,1,size=[1,2])\n",
        "b = np.random.uniform(-1,1,size=[1,1])\n",
        "predicted_y = log_reg_predict(x,w,b)\n",
        "predicted_y.shape\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "fa4rUSs1boYi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi Class \n",
        "Consider the same problem, but with three classes instead of two. Now the computation graph would be like\n",
        "![alt text](https://www.dropbox.com/s/jryr9f7udnxuetq/computationGraph_LR_simplified_multi_class.png?dl=1)\n",
        "which means that there are three output nodes, one for the probability of each class. How would this work?\n",
        "\n",
        "As we discussed in the first part of the course, we need to train three distinct estimators, one for each class. \n",
        "\n",
        "{ w<sub>1</sub>, b<sub>1</sub> } => Class 1\n",
        "\n",
        "{ w<sub>2</sub>, b<sub>2</sub> } => Class 2\n",
        "\n",
        "{ w<sub>3</sub>, b<sub>3</sub> } => Class 3\n",
        "\n",
        "Just like before, each w<sub>i</sub> is a vector and each b<sub>i</sub> is a number. \n",
        "\n",
        "We can stack them together and make the matrix W with shape of (3,  n<sub>f</sub>) and \n",
        " the matrix B with shape of (3, 1). The rest would be the same. In fact our implementation of the logistic regression would not require any modification.  "
      ]
    },
    {
      "metadata": {
        "id": "wZl5ckz9sOn4",
        "colab_type": "code",
        "outputId": "38cd615c-428a-4203-ee3b-af9e12baa796",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "n_s = 100  # number of samples\n",
        "n_outputs = 3\n",
        "n_f= 2\n",
        "\n",
        "x = np.random.uniform(-1,1,size=[n_s,n_f])\n",
        "w = np.random.uniform(-1,1,size=[n_outputs,n_f])\n",
        "b = np.random.uniform(-1,1,size=[1, n_outputs])\n",
        "predicted_y = log_reg_predict(x,w,b)\n",
        "predicted_y.shape\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "CF9OFx9dszRz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Multi Layer\n",
        "\n",
        "Now consider the situation where two logistic regressions are compined to make a new estimator. \n",
        "\n",
        "That is, LR1 is applied to that innput features  and determine the probabilities of different classes. Then LR2 takes these probabilities as an input and based on that determine the probabilities of  a second classification problem. \n",
        "The computation graph would look like\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/9o01doidvs6hmj9/computationGraph_LR_simplified_multi_layer.png?dl=1)  \n",
        "  \n",
        "For charachterization of this estimator, we need two sets of W and B matrices, one for the LR1 and one for LR2. We use the following notation for that:\n",
        "\n",
        "W<sup>[1]</sup> => Weights for LR1\n",
        "\n",
        "B<sup>[1]</sup> => Biases for LR1\n",
        "\n",
        "W<sup>[2]</sup> => Weights for LR1\n",
        "\n",
        "W<sup>[2]</sup> => Biases for LR1\n",
        "\n",
        "As discussed before, W<sup>[1]</sup> is \n",
        "\n",
        "{ w<sup>[1]</sup><sub>1</sub>, b<sub>1</sub> } => Class 1\n",
        "\n",
        "{ w<sup>[1]</sup><sub>2</sub>, b<sub>2</sub> } => Class 2\n",
        "\n",
        "{ w<sup>[1]</sup><sub>3</sub>, b<sub>3</sub> } => Class 3\n",
        "\n",
        "So, each w<sup>[j]</sup><sub>i</sub> is a vector and each b<sup>[j]</sup><sub>i</sub> is a number and they correspond to classification of class i for LR_j. \n",
        "\n",
        "Use what we haev done so far to implement this! \n",
        "\n",
        "(Optional) Design your function such that it work for n_s samples. "
      ]
    },
    {
      "metadata": {
        "id": "S5cmPy9XpZMl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def NN_forward(X, w_list, b_list):\n",
        "  a = []\n",
        "  a += [X]\n",
        "  for i in range(len(w_list)):\n",
        "    a += [log_reg_predict(a[-1], w_list[i], b_list[i])]\n",
        "  \n",
        "  return a\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AUuh38bzGtyj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0990790-8d4c-4e80-e9ff-9581c943193b"
      },
      "cell_type": "code",
      "source": [
        "n_s = 100  # number of samples\n",
        "n_outputs = 3\n",
        "n_f = 2\n",
        "n_l = [n_f, 5, 6, n_outputs ]\n",
        "\n",
        "x = np.random.uniform(-1,1,size=[n_s,n_f])\n",
        "w_list = [ np.random.uniform(-1,1,size=[ n_l[i+1] , n_l[i] ] ) for i in range(len(n_l) - 1 )  ]\n",
        "b_list = [ np.random.uniform(-1,1,size=[1, n_l[i+1]  ]) for i in range(len(n_l) - 1 )  ]\n",
        "\n",
        "# [print(w.shape) for w in w_list]\n",
        "# [print(w.shape) for w in b_list]\n",
        "\n",
        "# predicted_y = log_reg_predict(x,w,b)\n",
        "# predicted_y.shape\n",
        "a = NN_forward(x, w_list, b_list)\n",
        "a[-1].shape\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "_vniOtSb8Y4B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training a logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "VD98XP_h8Y3p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss"
      ]
    },
    {
      "metadata": {
        "id": "XVew7Bel8Y3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "We need to define our loss function for training. \n",
        "We use the cross-entropy. \n",
        "'''\n",
        "\n",
        "def cross_entropy(y, a):\n",
        "    return -y*np.log(a)- (1-y)*np.log(1-a)\n",
        "\n",
        "\n",
        "def cross_entropy_loss(y_list, x_list, w, bias=0):\n",
        "                  \n",
        "    ''' \n",
        "    First, you need to calculate the a = sig(z).\n",
        "    Then calculate the loss using the equation for cross entropy. \n",
        "    \n",
        "    '''\n",
        "    n_sample = len(y_list)\n",
        "    y_list = y_list.reshape(n_sample,1)\n",
        "    \n",
        "    z_list = ( np.dot(x_list, w.T ) + bias ).reshape( -1  , 1 )\n",
        "    a_list = sigmoid( z_list )\n",
        "    \n",
        "    loss = cross_entropy(y_list, a_list).sum() / n_sample\n",
        "    return loss\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tnVjWh-V8Y3x",
        "colab_type": "code",
        "outputId": "e7769fa7-717c-44cf-b221-c16cb6c08516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "n_s=1000\n",
        "x = np.random.uniform(-1,1,size=[n_s,2])\n",
        "w_list = np.random.uniform(-20,20,size=[100, 1, 2])\n",
        "ce_loss_list = [ cross_entropy_loss( predicted_y, x, w, b)  for w in w_list]\n",
        "\n",
        "w = np.random.uniform(-1,1,size=[1,2])\n",
        "b = np.random.uniform(-1,1,size=[1,1])\n",
        "\n",
        "predicted_y = log_reg_predict(x,w,b)\n",
        "print(w_list.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 1, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "onfOYDmYLibw",
        "colab_type": "code",
        "outputId": "e27bea3d-1338-455c-f2b0-41074afdbd09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "w_list[:,:,0].reshape(-1).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "3CdCKSZMJyTW",
        "colab_type": "code",
        "outputId": "0955e2e9-2694-4cf0-9cd5-6db9c68aa7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "cell_type": "code",
      "source": [
        "# ce_loss_list = [ cross_entropy_loss( predicted_y, x, w, b)  for w in w_list]\n",
        "\n",
        "\n",
        "print('The true parameters are \\n w={} which is in dicated by the red point.'.format(w.reshape(1,-1)))\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "ax1 = fig.add_subplot(111,title = 'Loss function \\n Cross_entropy', xlabel='w1', ylabel='w2')\n",
        "\n",
        "\n",
        "p1 = ax1.tricontourf(w_list[:,:,0].reshape(-1),w_list[:,:,1].reshape(-1), ce_loss_list)\n",
        "ax1.scatter(w[0,0], w[0,1], color='r')\n",
        "plt.colorbar(p1, ax=ax1)\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The true parameters are \n",
            " w=[[ 0.7613062  -0.58300925]] which is in dicated by the red point.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdUAAAGQCAYAAAD4LPooAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "7nYEna4RJkj1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Using an optimizer"
      ]
    },
    {
      "metadata": {
        "id": "LbMyB64W8Y4E",
        "colab_type": "code",
        "outputId": "e1a3c5bc-670a-4ad4-91e8-557ed656fff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from scipy.optimize import minimize\n",
        "print('The true parameters are \\n w = {}, \\n and b = {}. '.format(w.reshape(1,-1)[0] , b[0,0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The true parameters are \n",
            " w = [ 0.7613062  -0.58300925], \n",
            " and b = -0.025999105893764973. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "48_zzdKeM0KY",
        "colab_type": "code",
        "outputId": "b9fc9faf-074f-4648-ac83-5c1afe565515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "w = np.random.uniform(-1,1,size=[1,2])\n",
        "b = np.random.uniform(-1,1,size=[1,1])\n",
        "np.array([ [w[0,0],w[0,1]] ]).shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "91kzOXot8Y4M",
        "colab_type": "code",
        "outputId": "94b486e3-a5c0-48fb-dc38-abb4eacd8c6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "min_w = minimize( (lambda w: cross_entropy_loss(predicted_y, x, np.array([ [w[0],w[1]] ]),w[2] )),[0,0, 0])\n",
        "print('The optimized values are: w1, w2, b = {}'.format(min_w.x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimized values are: w1, w2, b = [ 0.76129796 -0.58296354 -0.0260065 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ps8F7llJ8Y4T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Step-by-Step GD for Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "p69IwHv4NhFs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we want to do this ourselves, not using the optimizer. \n",
        "\n",
        "We will use a simple GD algorithm which basically does the following:\n",
        "\n",
        "w_1  -> w_1 - alpha * dL/dw_1\n",
        "\n",
        "w_2  -> w_2 - alpha * dL/dw_2"
      ]
    }
  ]
}